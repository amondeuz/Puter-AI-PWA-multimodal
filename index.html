<!DOCTYPE html>
<html lang="en">
<link rel="manifest" href="manifest.json" />

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Puter AI</title>
  <meta name="description"
        content="Puter AI is an artificial intelligence powered by Puter. It can speak in multiple languages, like english, french, spanish, and many more !" />
  <link rel="icon" type="image/vnd.icon" href="favicon.ico">
  <script>console.log("Puter AI PWA started, ready to send messages.")</script>
  <meta name="google-site-verification" content="4qYi8tV9qUrPc5wpGixLaQov5gavq6HbwI8nGcN7b0c" />
  <meta name="google-site-verification" content="Q71qMHrmXHVJS96xLobvU5PdXHzkR23IRRD6gykEZew" />

  <!-- Material Design Web CDN -->
  <script type="importmap">
    {
      "imports": {
        "@material/web/": "https://esm.run/@material/web/"
      }
    }
  </script>
  <script type="module">
    import '@material/web/all.js';
    import { styles as typescaleStyles } from '@material/web/typography/md-typescale-styles.js';

    document.adoptedStyleSheets.push(typescaleStyles.styleSheet);
  </script>

  <!-- Noto Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link
    href="https://fonts.googleapis.com/css2?family=Noto+Color+Emoji&family=Noto+Sans&display=swap"
    rel="stylesheet">
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  <style>
    body {
      font-family: 'Noto Sans', sans-serif;
      margin: 0;
      padding: 0;
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100vh;
      background-color: #f0f0f0;
      flex-direction: column;
    }

    #chat-container {
      width: 80%;
      max-width: 600px;
      margin: auto;
      background: white;
      border: 1px solid #ddd;
      border-radius: 30px;
      padding: 20px;
      box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
    }

    #messages {
      height: 320px;
      overflow-y: auto;
      border-bottom: 1px solid #ddd;
      margin-bottom: 20px;
      padding: 10px;
    }

    .message {
      padding: 5px;
      margin: 5px 0;
      border-radius: 10px;
      background: #2c7aef;
      color: white;
    }

    .user-message {
      text-align: right;
      background: #f9f9f9;
      color: black;
    }

    .user-message .message {
      background: #e0f7fa;
    }

    #chat-input {
      display: flex;
      align-items: center;
      margin-top: 10px;
    }

    #chat-input md-outlined-text-field {
      flex-grow: 1;
      margin-right: 10px;
      max-width: 489px;
      min-height: 78px;
      max-height: 686px;
      --md-filled-text-field-input-text-font: 'Noto Sans', sans-serif;
      --md-filled-text-field-label-text-font: 'Noto Sans', sans-serif;
    }

    #chat-input md-filled-button {
      padding: 10px 20px;
      height: 52px;
    }

    md-filled-button,
    md-outlined-button,
    md-outlined-icon-button {
      --mdc-theme-primary: #007bff;
      --mdc-theme-on-primary: white;
      font-family: 'Noto Sans', sans-serif;
    }

    md-outlined-button {
      margin-top: 4px;
    }

    a {
      color: #007bff;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    :root {
      --md-sys-color-primary: #007bff;
      --md-sys-color-secondary: #007bffdc;
      --md-ref-typeface-brand: 'Noto Sans';
      --md-ref-typeface-plain: 'Noto Sans';
    }

    #icon-buttons {
      display: flex;
      gap: 10px;
      margin-top: 20px;
    }

    #loading-spinner {
      display: none;
      margin-top: 20px;
    }

    #mode-controls {
      display: flex;
      flex-direction: column;
      gap: 8px;
      margin-bottom: 10px;
      font-size: 0.9rem;
    }

    .control-row {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      align-items: center;
    }

    .control-row label {
      font-size: 0.9rem;
    }

    .mode-options {
      display: none;
    }

    .mode-options.active {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      align-items: center;
    }

    #default-buttons {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
    }

    select,
    input[type="text"] {
      font-family: 'Noto Sans', sans-serif;
      font-size: 0.9rem;
      padding: 4px 6px;
    }

    #file-inputs {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
    }

    #file-inputs label {
      font-size: 0.9rem;
    }

    audio,
    video,
    img {
      max-width: 100%;
      border-radius: 10px;
    }

    .help-text {
      font-size: 0.8rem;
      color: #555;
      width: 100%;
    }

    #openaiVoiceRow,
    #customVoiceRow {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      align-items: center;
    }
  </style>

  <script src="https://js.puter.com/v2/"></script>
</head>

<body>
<script>
  if (typeof navigator.serviceWorker !== 'undefined') {
    navigator.serviceWorker.register('sw.js')
  }
</script>
<div id="chat-container">

  <!-- Mode + model controls -->
  <div id="mode-controls">
    <div class="control-row">
      <label for="modeSelect">Mode:</label>
      <select id="modeSelect">
        <option value="chat">Chat (Text → Text)</option>
        <option value="txt2img">Text → Image</option>
        <option value="img2txt">Image → Text (OCR)</option>
        <option value="txt2speech">Text → Speech</option>
        <option value="speech2txt">Speech → Text</option>
        <option value="txt2vid">Text → Video</option>
      </select>
      <md-outlined-button id="refreshModelsButton">Refresh models</md-outlined-button>
    </div>

    <div id="chatOptions" class="mode-options">
      <label for="chatScopeSelect">Source:</label>
      <select id="chatScopeSelect">
        <option value="direct">Direct (non-OpenRouter)</option>
        <option value="openrouter">OpenRouter</option>
      </select>

      <label for="chatCompanySelect">Company / namespace:</label>
      <select id="chatCompanySelect">
        <option value="__all">All companies</option>
      </select>

      <label for="chatModelSelect">Model:</label>
      <select id="chatModelSelect">
        <!-- Populated from live model list -->
      </select>

      <span class="help-text">
        Models are loaded live from Puter - the list comes from
        <code>https://puter.com/puterai/chat/models</code>. Source splits OpenRouter models from everything
        else, and the company field groups providers under OpenRouter.
      </span>
    </div>


    <div id="imageOptions" class="mode-options">
      <label for="imageModelSelect">Image model:</label>
      <select id="imageModelSelect">
        <option value="gpt-image-1-mini" title="OpenAI GPT Image-1 mini – fast, lower cost">
          gpt-image-1-mini (OpenAI, fast)
        </option>
        <option value="gpt-image-1" title="OpenAI GPT Image-1 – higher quality">
          gpt-image-1 (OpenAI, quality)
        </option>
        <option value="dall-e-3" title="OpenAI DALL·E 3">
          dall-e-3 (DALL·E 3)
        </option>
        <option value="dall-e-2" title="OpenAI DALL·E 2">
          dall-e-2 (DALL·E 2)
        </option>
        <option value="gemini-2.5-flash-image-preview" title="Google Gemini 2.5 Flash Image (Nano Banana)">
          gemini-2.5-flash-image-preview (Gemini 2.5)
        </option>
        <option value="google/gemini-3-pro-image" title="Google Gemini 3 Pro Image (Nano Banana Pro)">
          google/gemini-3-pro-image (Gemini 3 Pro)
        </option>
        <option value="ByteDance-Seed/Seedream-3.0" title="ByteDance Seedream 3.0">
          ByteDance-Seed/Seedream-3.0
        </option>
        <option value="ByteDance-Seed/Seedream-4.0" title="ByteDance Seedream 4.0">
          ByteDance-Seed/Seedream-4.0
        </option>
        <option value="HiDream-ai/HiDream-I1-Dev" title="HiDream I1 Dev">
          HiDream-ai/HiDream-I1-Dev
        </option>
        <option value="HiDream-ai/HiDream-I1-Fast" title="HiDream I1 Fast">
          HiDream-ai/HiDream-I1-Fast
        </option>
        <option value="HiDream-ai/HiDream-I1-Full" title="HiDream I1 Full">
          HiDream-ai/HiDream-I1-Full
        </option>
        <option value="Lykon/DreamShaper" title="DreamShaper (Stable Diffusion style)">
          Lykon/DreamShaper
        </option>
        <option value="Qwen/Qwen-Image" title="Qwen Image model">
          Qwen/Qwen-Image
        </option>
        <option value="RunDiffusion/Juggernaut-pro-flux" title="Flux-based Juggernaut Pro">
          RunDiffusion/Juggernaut-pro-flux
        </option>
        <option value="Rundiffusion/Juggernaut-Lightning-Flux" title="Flux-based Juggernaut Lightning">
          Rundiffusion/Juggernaut-Lightning-Flux
        </option>
      </select>
      <span class="help-text">
        GPT Image / DALL·E are OpenAI models; Gemini entries are Google; Seedream, Flux, DreamShaper, Qwen
        and HiDream come from the generic Image Generation API. 
      </span>
    </div>

    <div id="ocrOptions" class="mode-options">
      <label for="ocrProviderSelect">OCR provider:</label>
      <select id="ocrProviderSelect">
        <option value="aws-textract">aws-textract (default)</option>
        <option value="mistral">mistral (multilingual / rich)</option>
      </select>
      <label for="ocrModelSelect">Mistral model:</label>
      <select id="ocrModelSelect">
        <option value="mistral-ocr-latest">mistral-ocr-latest (default)</option>
        <option value="__custom">Custom…</option>
      </select>
      <input id="ocrModelInput" type="text" placeholder="Custom Mistral OCR model id"
             style="display:none;" />
      <span class="help-text">
        For AWS Textract, model is fixed. For Mistral, the default is <code>mistral-ocr-latest</code>;
        choose Custom to supply a different model id. 
      </span>
    </div>

    <div id="ttsOptions" class="mode-options">
      <label for="ttsProviderSelect">TTS provider:</label>
      <select id="ttsProviderSelect">
        <option value="aws-polly">aws-polly (default)</option>
        <option value="openai">openai</option>
        <option value="elevenlabs">elevenlabs</option>
      </select>

      <label for="ttsModelSelect">TTS model (OpenAI / ElevenLabs):</label>
      <select id="ttsModelSelect">
        <option value="gpt-4o-mini-tts">gpt-4o-mini-tts (OpenAI)</option>
        <option value="tts-1">tts-1 (OpenAI)</option>
        <option value="tts-1-hd">tts-1-hd (OpenAI)</option>
        <option value="eleven_multilingual_v2">eleven_multilingual_v2 (ElevenLabs)</option>
      </select>

      <label for="ttsLanguageInput">Language (AWS code):</label>
      <input id="ttsLanguageInput" type="text" value="en-US" />

      <div id="openaiVoiceRow">
        <label for="openaiVoiceSelect">OpenAI voice:</label>
        <select id="openaiVoiceSelect">
          <option value="alloy">alloy</option>
          <option value="ash">ash</option>
          <option value="ballad">ballad</option>
          <option value="coral">coral</option>
          <option value="echo">echo</option>
          <option value="fable">fable</option>
          <option value="nova">nova</option>
          <option value="onyx">onyx</option>
          <option value="sage">sage</option>
          <option value="shimmer">shimmer</option>
        </select>
      </div>

      <div id="customVoiceRow">
        <label for="ttsVoiceInput">Voice (Polly name or ElevenLabs ID):</label>
        <input id="ttsVoiceInput" type="text" placeholder="Joanna for Polly, or ElevenLabs voice id" />
      </div>

      <span class="help-text">
        AWS Polly uses <code>language</code> and a voice name (for example Joanna). OpenAI uses a TTS model
        plus one of the documented built-in voices. ElevenLabs uses <code>eleven_multilingual_v2</code> plus
        your chosen voice ID.
      </span>
    </div>

    <div id="sttOptions" class="mode-options">
      <label for="sttModelSelect">Speech-to-text model:</label>
      <select id="sttModelSelect">
        <option value="gpt-4o-mini-transcribe">gpt-4o-mini-transcribe (fast)</option>
        <option value="gpt-4o-transcribe">gpt-4o-transcribe (quality)</option>
        <option value="gpt-4o-transcribe-diarize">gpt-4o-transcribe-diarize (speaker diarization)</option>
        <option value="whisper-1">whisper-1</option>
      </select>
      <label for="sttLanguageInput">Language hint (optional):</label>
      <input id="sttLanguageInput" type="text" placeholder="e.g. en, es, fr" />
      <label for="sttResponseFormatSelect">Response format:</label>
      <select id="sttResponseFormatSelect">
        <option value="text">text (plain)</option>
        <option value="json">json</option>
        <option value="diarized_json">diarized_json</option>
        <option value="srt">srt (subtitles)</option>
        <option value="vtt">vtt (subtitles)</option>
      </select>
      <label><input type="checkbox" id="sttTranslateCheckbox">
        Force English output (translate)
      </label>
      <span class="help-text">
        These models map directly to <code>puter.ai.speech2txt()</code>’s supported list. Use diarize for
        multi-speaker audio or subtitle formats when you want timecodes. 
      </span>
    </div>

    <div id="videoOptions" class="mode-options">
      <label for="videoModelSelect">Video model:</label>
      <select id="videoModelSelect">
        <option value="sora-2">sora-2 (OpenAI)</option>
        <option value="sora-2-pro">sora-2-pro (OpenAI)</option>
        <option value="ByteDance/Seedance-1.0-lite">ByteDance/Seedance-1.0-lite (fast)</option>
        <option value="ByteDance/Seedance-1.0-pro">ByteDance/Seedance-1.0-pro (quality)</option>
        <option value="Wan-AI/Wan2.2-T2V-A14B">Wan-AI/Wan2.2-T2V-A14B</option>
      </select>
      <span class="help-text">
        Sora models are from OpenAI. Seedance and Wan models come from the generic text to video API family and
        are exposed through <code>puter.ai.txt2vid()</code>.
      </span>
    </div>

    <div id="file-inputs">
      <div id="imageInputWrapper" style="display:none;">
        <label for="imageInput">Image file:</label>
        <input type="file" id="imageInput" accept="image/*">
      </div>
      <div id="audioInputWrapper" style="display:none;">
        <label for="audioInput">Audio file:</label>
        <input type="file" id="audioInput" accept="audio/*">
      </div>
    </div>

    <div id="default-buttons">
      <md-outlined-button id="saveDefaultButton">Save as default</md-outlined-button>
      <md-outlined-button id="resetDefaultButton">Reset to default</md-outlined-button>
    </div>
  </div>

  <div id="messages"></div>

  <div id="chat-input">
    <md-outlined-text-field label="Message" placeholder="Type a message..." id="messageInput"
                            error-text="Please type a message"
                            style="font-family: 'Noto Sans', sans-serif;"></md-outlined-text-field>
    <md-filled-button id="sendButton" style="font-family: 'Noto Sans', sans-serif;">Send
      <img slot="icon" src="icons/send.png" alt="Send Icon" />
    </md-filled-button>
  </div>
</div>
<p>AI can make mistakes, please check important information.</p>
<div id="loading-spinner">
  <md-circular-progress indeterminate></md-circular-progress>
</div>
<div id="icon-buttons">
  <md-outlined-icon-button aria-label="Settings" href="settings.html">
    <md-icon class="material-icons">settings</md-icon>
  </md-outlined-icon-button>
  <md-outlined-icon-button aria-label="Github" href="https://github.com/Zac0511/Puter-AI-PWA">
    <md-icon class="material-icons">code</md-icon>
  </md-outlined-icon-button>
</div>
<p>Powered by <a href="https://puter.com">Puter</a></p>

<script type="module">
  const LOCAL_STORAGE_KEY = 'puter-ai-pwa-defaults-v2';

  const BUILT_IN_DEFAULTS = {
    mode: 'chat',
    chatScope: 'direct',
    chatCompany: '__all',
    chatModel: '',
    imageModel: 'gpt-image-1-mini',
    ocrProvider: 'aws-textract',
    ocrModel: 'mistral-ocr-latest',
    ttsProvider: 'aws-polly',
    ttsModel: 'gpt-4o-mini-tts',
    ttsLanguage: 'en-US',
    ttsVoice: '',
    videoModel: 'sora-2',
    sttModel: 'gpt-4o-mini-transcribe',
    sttLanguage: '',
    sttResponseFormat: 'text',
    sttTranslate: false
  };

  // Live model cache
  let CHAT_MODEL_DATA = [];

  const SYSTEM_MESSAGES = [
    {
      role: 'system',
      content: "You are the AI of a PWA named 'Puter AI PWA' developed by 'Zac0511'.The PWA is powered by Puter.js, allowing websites to use AI for free. You need to remember that Zac0511 is not the one who created you, he only made the PWA which interacts with you thanks to Puter.js, your creator is a company called 'Puter'. Puter is web based operationg system, entierly running in the browser, its creators are only 3 persons, but the projects grows fast as its open source, and more 2000 users contributed to it (including Zac0511, the creator of this PWA). Puter.js is Puter's API, allwoing websites to store files on the user's Puter filesystem, and access AI, which is why your creator is Puter. Your name is 'Puter AI'. Do NOT use Markdown formatting, the PWA in which you run doesn't support markdown."
    },
    {
      role: 'system',
      content: "The following is complementary informations about Puter: The URL to access Puter is 'https://puter.com'. Puter is web-based OS running entierly in the browser. You have been created by Puter. Puter was originally made by only 3 persons, but grows fast because it is open source. Puter has hundreds of thousands of users. The URL to join Puter's Discord server is 'https://discord.gg/PQcx7Teh8u'"
    },
    {
      role: 'system',
      content: "The following is complementary informations about the Puter AI PWA: The current version of the Puter AI PWA is version 2.2.3. The creator of the Puter AI PWA is 'Zac0511'. The Puter AI PWA can be installed on computer and mobile, but it can also be runned (without being installed) on any device with a recent browser (such as computers, phones, consoles, TVs, etc...). The Puter AI PWA can be used without a Puter account, but the user will have less message credits. The user can check how many messages credits are left on his Puter account by opening Puter, clicking the Puter logo in the top left corner (it will open settings), clicking 'Usage' in the settings, and checking the bar named 'puter-chat-completion (complete):'. The Puter AI PWA is also available as a Puter app at the URL 'https://puter.com/app/ai-chat'. The UI of the Puter AI PWA is using Google Material Design V3. The PWA cannot be used offline, as the AI is stored on Puter servers (trying to open the app when offline will show a custom error message). If the user encounters any problem with the Puter AI PWA, or ask for a new feature, he can create an issue at the URL 'https://github.com/Zac0511/Puter-AI-PWA/issues/new/choose'."
    }
  ];

  function addMessage(msg, isUser) {
    if (!msg && msg !== '') return;
    const messagesDiv = document.getElementById("messages");
    const wrapper = document.createElement("div");
    wrapper.classList.add("message");
    if (isUser) wrapper.classList.add("user-message");
    wrapper.textContent = msg;
    messagesDiv.appendChild(wrapper);
    messagesDiv.scrollTop = messagesDiv.scrollHeight;
  }

  function addElementMessage(element) {
    const messagesDiv = document.getElementById("messages");
    const wrapper = document.createElement("div");
    wrapper.classList.add("message");
    wrapper.appendChild(element);
    messagesDiv.appendChild(wrapper);
    messagesDiv.scrollTop = messagesDiv.scrollHeight;
  }

  function toggleLoadingSpinner(show) {
    const spinner = document.getElementById('loading-spinner');
    spinner.style.display = show ? 'block' : 'none';
  }

  function getCurrentSettingsFromUI() {
    return {
      mode: document.getElementById('modeSelect').value,
      chatScope: document.getElementById('chatScopeSelect').value,
      chatCompany: document.getElementById('chatCompanySelect').value,
      chatModel: document.getElementById('chatModelSelect').value,
      imageModel: document.getElementById('imageModelSelect').value,
      ocrProvider: document.getElementById('ocrProviderSelect').value,
      ocrModel: document.getElementById('ocrModelSelect').value,
      ttsProvider: document.getElementById('ttsProviderSelect').value,
      ttsModel: document.getElementById('ttsModelSelect').value,
      ttsLanguage: document.getElementById('ttsLanguageInput').value,
      ttsVoice: document.getElementById('ttsVoiceInput').value,
      videoModel: document.getElementById('videoModelSelect').value,
      sttModel: document.getElementById('sttModelSelect').value,
      sttLanguage: document.getElementById('sttLanguageInput').value,
      sttResponseFormat: document.getElementById('sttResponseFormatSelect').value,
      sttTranslate: document.getElementById('sttTranslateCheckbox').checked
    };
  }

  function applySettingsToUI(settings) {
    const s = { ...BUILT_IN_DEFAULTS, ...settings };

    document.getElementById('modeSelect').value = s.mode;

    // Scope and company are applied before we build the model list
    const scopeSel = document.getElementById('chatScopeSelect');
    const companySel = document.getElementById('chatCompanySelect');
    if (scopeSel) scopeSel.value = s.chatScope;
    if (companySel) companySel.value = s.chatCompany;

    document.getElementById('imageModelSelect').value = s.imageModel;
    document.getElementById('ocrProviderSelect').value = s.ocrProvider;
    document.getElementById('ocrModelSelect').value = s.ocrModel;
    document.getElementById('ttsProviderSelect').value = s.ttsProvider;
    document.getElementById('ttsModelSelect').value = s.ttsModel;
    document.getElementById('ttsLanguageInput').value = s.ttsLanguage;
    document.getElementById('ttsVoiceInput').value = s.ttsVoice;
    document.getElementById('videoModelSelect').value = s.videoModel;
    document.getElementById('sttModelSelect').value = s.sttModel;
    document.getElementById('sttLanguageInput').value = s.sttLanguage;
    document.getElementById('sttResponseFormatSelect').value = s.sttResponseFormat;
    document.getElementById('sttTranslateCheckbox').checked = s.sttTranslate;

    handleOcrModelVisibility();
    updateModeVisibility();
    updateTtsUi();
  }

  function loadDefaults() {
    try {
      const raw = localStorage.getItem(LOCAL_STORAGE_KEY);
      if (!raw) return { ...BUILT_IN_DEFAULTS };
      const parsed = JSON.parse(raw);
      return { ...BUILT_IN_DEFAULTS, ...parsed };
    } catch (e) {
      console.error('Unable to load defaults', e);
      return { ...BUILT_IN_DEFAULTS };
    }
  }

  function saveDefaultsFromUI() {
    const settings = getCurrentSettingsFromUI();
    try {
      localStorage.setItem(LOCAL_STORAGE_KEY, JSON.stringify(settings));
      alert('Defaults saved.');
    } catch (e) {
      console.error('Unable to save defaults', e);
      alert('Unable to save defaults (see console).');
    }
  }

  function resetDefaults() {
    try {
      localStorage.setItem(LOCAL_STORAGE_KEY, JSON.stringify(BUILT_IN_DEFAULTS));
    } catch (e) {
      console.error('Unable to reset defaults in storage', e);
    }
    applySettingsToUI(BUILT_IN_DEFAULTS);
  }

  function updateModeVisibility() {
    const mode = document.getElementById('modeSelect').value;

    const chatOptions = document.getElementById('chatOptions');
    const imageOptions = document.getElementById('imageOptions');
    const ocrOptions = document.getElementById('ocrOptions');
    const ttsOptions = document.getElementById('ttsOptions');
    const sttOptions = document.getElementById('sttOptions');
    const videoOptions = document.getElementById('videoOptions');
    const imageInputWrapper = document.getElementById('imageInputWrapper');
    const audioInputWrapper = document.getElementById('audioInputWrapper');

    chatOptions.classList.remove('active');
    imageOptions.classList.remove('active');
    ocrOptions.classList.remove('active');
    ttsOptions.classList.remove('active');
    sttOptions.classList.remove('active');
    videoOptions.classList.remove('active');
    imageInputWrapper.style.display = 'none';
    audioInputWrapper.style.display = 'none';

    if (mode === 'chat') {
      chatOptions.classList.add('active');
    } else if (mode === 'txt2img') {
      imageOptions.classList.add('active');
    } else if (mode === 'img2txt') {
      ocrOptions.classList.add('active');
      imageInputWrapper.style.display = 'block';
    } else if (mode === 'txt2speech') {
      ttsOptions.classList.add('active');
    } else if (mode === 'speech2txt') {
      sttOptions.classList.add('active');
      audioInputWrapper.style.display = 'block';
    } else if (mode === 'txt2vid') {
      videoOptions.classList.add('active');
    }
  }

  function handleOcrModelVisibility() {
    const provider = document.getElementById('ocrProviderSelect').value;
    const ocrModelSelect = document.getElementById('ocrModelSelect');
    const ocrModelInput = document.getElementById('ocrModelInput');

    if (provider === 'mistral') {
      ocrModelSelect.disabled = false;
      if (ocrModelSelect.value === '__custom') {
        ocrModelInput.style.display = 'inline-block';
      } else {
        ocrModelInput.style.display = 'none';
      }
    } else {
      ocrModelSelect.disabled = true;
      ocrModelInput.style.display = 'none';
    }
  }

  function updateTtsUi() {
    const provider = document.getElementById('ttsProviderSelect').value;
    const ttsModelSelect = document.getElementById('ttsModelSelect');
    const ttsLanguageInput = document.getElementById('ttsLanguageInput');
    const openaiVoiceRow = document.getElementById('openaiVoiceRow');
    const openaiVoiceSelect = document.getElementById('openaiVoiceSelect');
    const customVoiceRow = document.getElementById('customVoiceRow');
    const customVoiceInput = document.getElementById('ttsVoiceInput');

    if (provider === 'openai') {
      Array.from(ttsModelSelect.options).forEach(opt => {
        const isOpenAi = opt.value === 'gpt-4o-mini-tts' ||
          opt.value === 'tts-1' ||
          opt.value === 'tts-1-hd';
        opt.disabled = !isOpenAi;
      });
      if (ttsModelSelect.value === 'eleven_multilingual_v2') {
        ttsModelSelect.value = 'gpt-4o-mini-tts';
      }
      ttsModelSelect.disabled = false;

      ttsLanguageInput.disabled = true;
      ttsLanguageInput.style.opacity = '0.5';

      openaiVoiceRow.style.opacity = '1';
      openaiVoiceSelect.disabled = false;

      customVoiceRow.style.opacity = '0.5';
      customVoiceInput.disabled = true;
    } else if (provider === 'elevenlabs') {
      ttsModelSelect.value = 'eleven_multilingual_v2';
      ttsModelSelect.disabled = true;

      ttsLanguageInput.disabled = true;
      ttsLanguageInput.style.opacity = '0.5';

      openaiVoiceRow.style.opacity = '0.5';
      openaiVoiceSelect.disabled = true;

      customVoiceRow.style.opacity = '1';
      customVoiceInput.disabled = false;
      if (!customVoiceInput.value) {
        customVoiceInput.value = '21m00Tcm4TlvDq8ikWAM';
      }
    } else {
      // aws-polly
      ttsModelSelect.disabled = true;

      ttsLanguageInput.disabled = false;
      ttsLanguageInput.style.opacity = '1';

      openaiVoiceRow.style.opacity = '0.5';
      openaiVoiceSelect.disabled = true;

      customVoiceRow.style.opacity = '1';
      customVoiceInput.disabled = false;
    }
  }

  // ---------- Chat model hierarchy from live endpoint ----------

  // Fallback models when CORS blocks dynamic fetch (for GitHub Pages, etc.)
  const FALLBACK_CHAT_MODELS = [
    // Claude models (Anthropic)
    'claude-sonnet-4-20250514',
    'claude-3-5-sonnet-20241022',
    'claude-3-5-sonnet-20240620',
    'claude-3-opus-20240229',
    'claude-3-sonnet-20240229',
    'claude-3-haiku-20240307',
    
    // GPT models (OpenAI)
    'gpt-4o',
    'gpt-4o-mini',
    'gpt-4-turbo',
    'gpt-4',
    'gpt-3.5-turbo',
    
    // Gemini models (Google)
    'gemini-2.5-flash',
    'gemini-2.0-flash-exp',
    'gemini-1.5-pro',
    'gemini-1.5-flash',
    
    // Llama models (Meta) via OpenRouter
    'openrouter:meta-llama/llama-3.3-70b-instruct',
    'openrouter:meta-llama/llama-3.2-90b-vision-instruct',
    'openrouter:meta-llama/llama-3.1-405b-instruct',
    
    // Qwen models via OpenRouter
    'openrouter:qwen/qwen-2.5-72b-instruct',
    
    // DeepSeek models via OpenRouter
    'openrouter:deepseek/deepseek-chat',
    
    // Mistral models via OpenRouter
    'openrouter:mistralai/mistral-large',
    
    // Others
    'openrouter:google/gemini-pro-1.5',
    'openrouter:anthropic/claude-3.5-sonnet'
  ];

    // Try live Puter endpoint first, then local models.json, then hardcoded fallback
  async function loadModelList() {
    // 1) Live endpoint from Puter
    try {
      const res = await fetch('https://puter.com/puterai/chat/models', { cache: 'no-store' });
      if (res.ok) {
        const json = await res.json();
        if (Array.isArray(json.models)) {
          console.log('Loaded live model list from puter.com');
          return json.models;
        }
        console.warn('Live endpoint did not return models[] array');
      } else {
        console.warn('Live models endpoint returned', res.status, res.statusText);
      }
    } catch (e) {
      console.warn('Error calling live models endpoint (likely CORS or network):', e);
    }

    // 2) Local models.json snapshot that you can update manually
    try {
      const res = await fetch('models.json', { cache: 'no-store' });
      if (res.ok) {
        const json = await res.json();
        if (Array.isArray(json.models)) {
          console.log('Loaded fallback model list from local models.json');
          return json.models;
        }
        console.warn('Local models.json did not contain models[] array');
      } else {
        console.warn('Local models.json fetch failed:', res.status, res.statusText);
      }
    } catch (e) {
      console.error('Error loading local models.json:', e);
    }

    // 3) Last resort: hardcoded fallback list (may be incomplete)
    console.warn('Falling back to hardcoded fallback chat models');
    return FALLBACK_CHAT_MODELS.slice();
  }

  function parseModelId(id) {
    const OPENROUTER_PREFIX = 'openrouter:';
    const result = {
      id,
      isOpenRouter: false,
      company: 'builtin',
      name: id
    };

    if (id.startsWith(OPENROUTER_PREFIX)) {
      result.isOpenRouter = true;
      const rest = id.slice(OPENROUTER_PREFIX.length);
      const slashIndex = rest.indexOf('/');
      if (slashIndex >= 0) {
        result.company = rest.slice(0, slashIndex);
        result.name = rest.slice(slashIndex + 1);
      } else {
        result.company = 'openrouter';
        result.name = rest;
      }
    }

    return result;
  }

      // Use the combined loader: live → models.json → fallback array
    const raw = await loadModelList();
    CHAT_MODEL_DATA = raw.map(parseModelId);

    if (!CHAT_MODEL_DATA.length) {
      console.error('No chat models available from live endpoint, models.json, or fallback list');
      return;
    }


    const matchingDefault = CHAT_MODEL_DATA.find(m => m.id === defaultModelId);
    if (matchingDefault) {
      defaultScope = matchingDefault.isOpenRouter ? 'openrouter' : 'direct';
      defaultCompany = matchingDefault.company;
    }

    function filteredModels(scope, company) {
      return CHAT_MODEL_DATA.filter(m => {
        if (scope === 'openrouter' && !m.isOpenRouter) return false;
        if (scope === 'direct' && m.isOpenRouter) return false;
        if (company && company !== '__all' && m.company !== company) return false;
        return true;
      });
    }

    function populateCompanies(scope, selectedCompany) {
      const models = filteredModels(scope, null);
      const companies = Array.from(new Set(models.map(m => m.company)))
        .sort((a, b) => a.localeCompare(b));

      companySelect.innerHTML = '';

      const allOpt = document.createElement('option');
      allOpt.value = '__all';
      allOpt.textContent = 'All companies';
      companySelect.appendChild(allOpt);

      companies.forEach(c => {
        const opt = document.createElement('option');
        opt.value = c;
        opt.textContent = c;
        companySelect.appendChild(opt);
      });

      if (selectedCompany && companies.includes(selectedCompany)) {
        companySelect.value = selectedCompany;
      } else {
        companySelect.value = '__all';
      }
    }

    function populateModels(scope, company, selectedId) {
      const models = filteredModels(scope, company).sort((a, b) => a.name.localeCompare(b.name));

      modelSelect.innerHTML = '';
      models.forEach(m => {
        const opt = document.createElement('option');
        opt.value = m.id;
        opt.textContent = m.name;
        modelSelect.appendChild(opt);
      });

      if (selectedId && models.some(m => m.id === selectedId)) {
        modelSelect.value = selectedId;
      } else if (models.length) {
        modelSelect.value = models[0].id;
      }
    }

    scopeSelect.onchange = () => {
      const scope = scopeSelect.value;
      populateCompanies(scope, null);
      populateModels(scope, companySelect.value, null);
    };

    companySelect.onchange = () => {
      const scope = scopeSelect.value;
      const company = companySelect.value;
      populateModels(scope, company, null);
    };

    scopeSelect.value = defaultScope;
    populateCompanies(defaultScope, defaultCompany);
    populateModels(defaultScope, companySelect.value, defaultModelId);
  }

  // ---------- Core send logic ----------

  async function sendMessage(message) {
    const input = document.querySelector("#messageInput");
    const mode = document.getElementById('modeSelect').value;
    let text = (message || input.value || "").trim();

    const imageFile = document.getElementById('imageInput').files[0];
    const audioFile = document.getElementById('audioInput').files[0];

    if (mode === 'chat' && !text) {
      return;
    }

    if (text) {
      addMessage(text, true);
      input.value = '';
    }

    if (mode === 'img2txt' && !imageFile) {
      alert('Please select an image file for OCR.');
      return;
    }
    if (mode === 'speech2txt' && !audioFile) {
      alert('Please select an audio file for transcription.');
      return;
    }

    console.log("Message sent to Puter AI, mode:", mode);
    toggleLoadingSpinner(true);

    try {
      if (mode === 'chat') {
        const chatModel = document.getElementById('chatModelSelect').value;
        const messagesPayload = [
          ...SYSTEM_MESSAGES,
          { role: 'user', content: text }
        ];
        const options = chatModel ? { model: chatModel } : {};
        const response = await puter.ai.chat(messagesPayload, options);
        addMessage(response, false);
      } else if (mode === 'txt2img') {
        const imgModel = document.getElementById('imageModelSelect').value;
        const img = await puter.ai.txt2img(text, { model: imgModel });
        addElementMessage(img);
      } else if (mode === 'img2txt') {
        const provider = document.getElementById('ocrProviderSelect').value;
        const ocrModelSel = document.getElementById('ocrModelSelect').value;
        const ocrModelCustom = document.getElementById('ocrModelInput').value.trim();
        const options = { provider };
        if (provider === 'mistral') {
          if (ocrModelSel === '__custom' && ocrModelCustom) {
            options.model = ocrModelCustom;
          } else if (ocrModelSel && ocrModelSel !== '__custom') {
            options.model = ocrModelSel;
          }
        }
        const result = await puter.ai.img2txt({ source: imageFile, ...options });
        addMessage(result, false);
      } else if (mode === 'txt2speech') {
        const provider = document.getElementById('ttsProviderSelect').value;
        const language = document.getElementById('ttsLanguageInput').value.trim();
        const customVoice = document.getElementById('ttsVoiceInput').value.trim();
        const ttsModel = document.getElementById('ttsModelSelect').value;
        const openaiVoice = document.getElementById('openaiVoiceSelect').value;

        let options;

        if (provider === 'openai') {
          options = {
            provider: 'openai',
            model: ttsModel || 'gpt-4o-mini-tts',
            voice: openaiVoice || 'alloy',
            response_format: 'mp3'
          };
        } else if (provider === 'elevenlabs') {
          options = {
            provider: 'elevenlabs',
            model: 'eleven_multilingual_v2',
            voice: customVoice || '21m00Tcm4TlvDq8ikWAM'
          };
        } else {
          options = {
            provider: 'aws-polly',
            language: language || 'en-US',
            voice: customVoice || 'Joanna'
          };
        }

        const audio = await puter.ai.txt2speech(text, options);
        audio.controls = true;
        addElementMessage(audio);
      } else if (mode === 'speech2txt') {
        const sttModel = document.getElementById('sttModelSelect').value;
        const sttLang = document.getElementById('sttLanguageInput').value.trim();
        const sttFormat = document.getElementById('sttResponseFormatSelect').value;
        const sttTranslate = document.getElementById('sttTranslateCheckbox').checked;

        const options = { model: sttModel };
        if (sttLang) options.language = sttLang;
        if (sttFormat) options.response_format = sttFormat;
        if (sttTranslate) options.translate = true;

        const result = await puter.ai.speech2txt(audioFile, options);
        let textOut;
        if (typeof result === 'string') {
          textOut = result;
        } else if (result && typeof result.text === 'string') {
          textOut = result.text;
        } else {
          textOut = JSON.stringify(result);
        }
        addMessage(textOut, false);
      } else if (mode === 'txt2vid') {
        const videoModel = document.getElementById('videoModelSelect').value;
        const video = await puter.ai.txt2vid(text, { model: videoModel });
        video.controls = true;
        addElementMessage(video);
      }
      console.log("AI response received");
    } catch (error) {
      console.error("AI response error:", error);
      alert("An error occured, please try again. If the error persists, please create an issue on the GitHub repository (you can access it by clicking the button with a 'code' icon)");
    } finally {
      toggleLoadingSpinner(false);
    }
  }

  function getQueryParam(param) {
    const urlParams = new URLSearchParams(window.location.search);
    return urlParams.get(param);
  }

  function initUI() {
    const defaults = loadDefaults();

    applySettingsToUI(defaults);

    // Initialize chat model selectors from live endpoint
    initChatModelSelectors(defaults);

    document.getElementById('modeSelect').addEventListener('change', updateModeVisibility);
    document.getElementById('saveDefaultButton').addEventListener('click', saveDefaultsFromUI);
    document.getElementById('resetDefaultButton').addEventListener('click', resetDefaults);

    document.getElementById('refreshModelsButton').addEventListener('click', () => {
      const current = getCurrentSettingsFromUI();
      initChatModelSelectors({
        chatScope: current.chatScope,
        chatCompany: current.chatCompany,
        chatModel: current.chatModel
      });
    });

    document.getElementById('ocrProviderSelect').addEventListener('change', handleOcrModelVisibility);
    document.getElementById('ocrModelSelect').addEventListener('change', handleOcrModelVisibility);

    document.getElementById('ttsProviderSelect').addEventListener('change', updateTtsUi);
    document.getElementById('ttsModelSelect').addEventListener('change', updateTtsUi);
  }

  document.querySelector("#messageInput").addEventListener("keypress", function (event) {
    if (event.key === "Enter" && !event.shiftKey) {
      event.preventDefault();
      sendMessage();
    }
  });

  document.querySelector('#sendButton').addEventListener('click', function () {
    sendMessage();
  });

  window.addEventListener('load', () => {
    initUI();
    const message = getQueryParam('message');
    if (message) {
      document.querySelector("#messageInput").value = message;
      sendMessage();
    }
  });
</script>

</body>

</html>
